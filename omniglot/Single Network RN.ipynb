{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import task_generator_rn as tgrn\n",
    "import os\n",
    "import math\n",
    "import argparse\n",
    "import random\n",
    "from tensorboardX import SummaryWriter\n",
    "# Hyper Parameters\n",
    "\n",
    "def get_cnn_output_dims(W, K, P, S):\n",
    "    return (int(W-K+2*P)/S)+1\n",
    "def cnn_final_output_dims(image_size):\n",
    "    dim1_calc = get_cnn_output_dims(image_size, 3, 0, 1)/2\n",
    "    dim2_calc = get_cnn_output_dims(dim1_calc, 3, 0, 1)/2\n",
    "    dim3_calc = get_cnn_output_dims(dim2_calc, 3, 1, 1)\n",
    "    final_output = get_cnn_output_dims(dim3_calc, 3, 1, 1)\n",
    "    return final_output\n",
    "def rn_dims_before_FCN(input_dims):\n",
    "    dim1_calc = get_cnn_output_dims(input_dims, 3, 1, 1)/2\n",
    "    final_output = get_cnn_output_dims(dim1_calc, 3, 1, 1)/2\n",
    "    return final_output\n",
    "\n",
    "CLASS_NUM = 5\n",
    "SAMPLE_NUM_PER_CLASS = 5\n",
    "QUERY_NUM_PER_CLASS = 10\n",
    "EPISODE = 1001\n",
    "TEST_EPISODE = 100\n",
    "LEARNING_RATE = 0.005\n",
    "NO_OF_TPU_CORES = 8\n",
    "GPU = 0\n",
    "HIDDEN_UNIT = 256\n",
    "IMAGE_SIZE = 28\n",
    "CHANNEL_DIM = 64\n",
    "DIMS = int(cnn_final_output_dims(IMAGE_SIZE))\n",
    "RN_DIMS = int(rn_dims_before_FCN(DIMS))\n",
    "FCN_SIZE = int(CHANNEL_DIM*(RN_DIMS**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from apex import amp\n",
    "    APEX_AVAILABLE = True\n",
    "except:\n",
    "    print ('Apex not available')\n",
    "    APEX_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Plus_RNEncoder(nn.Module):\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNN_Plus_RNEncoder, self).__init__()\n",
    "        self.cnn_layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(1,64,kernel_size=3,padding=0),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2))\n",
    "        self.cnn_layer2 = nn.Sequential(\n",
    "                        nn.Conv2d(64,64,kernel_size=3,padding=0),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2))\n",
    "        self.cnn_layer3 = nn.Sequential(\n",
    "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU())\n",
    "        self.cnn_layer4 = nn.Sequential(\n",
    "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU())\n",
    "        \n",
    "        #RelationNetwork\n",
    "        self.rn_layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(128,64,kernel_size=3,padding=1),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2))\n",
    "        self.rn_layer2 = nn.Sequential(\n",
    "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2))\n",
    "        self.rn_fc1 = nn.Linear(FCN_SIZE,HIDDEN_UNIT)\n",
    "        self.rn_fc2 = nn.Linear(HIDDEN_UNIT,1)\n",
    "\n",
    "    def forward(self, samples, batches):\n",
    "        #print (samples.size(), batches.size())\n",
    "        sample_features = self.cnn_layer1(samples)\n",
    "        sample_features = self.cnn_layer2(sample_features)\n",
    "        sample_features = self.cnn_layer3(sample_features)\n",
    "        sample_features = self.cnn_layer4(sample_features)\n",
    "        cnn_features = sample_features\n",
    "        \n",
    "        sample_features = sample_features.view(CLASS_NUM,SAMPLE_NUM_PER_CLASS,CHANNEL_DIM, DIMS, DIMS)\n",
    "        sample_features = torch.sum(sample_features,1).squeeze(1)\n",
    "        \n",
    "        #batch features calculated from test for RN\n",
    "        batch_features = batches\n",
    "        batch_features = self.cnn_layer1(batch_features)\n",
    "        batch_features = self.cnn_layer2(batch_features)\n",
    "        batch_features = self.cnn_layer3(batch_features)\n",
    "        batch_features = self.cnn_layer4(batch_features)\n",
    "        cnn_batch_features = batch_features\n",
    "\n",
    "        # calculate relations\n",
    "        # each batch sample link to every samples to calculate relations\n",
    "        # to form a matrix for relation network\n",
    "        sample_features_ext = sample_features.unsqueeze(0).repeat((QUERY_NUM_PER_CLASS)*CLASS_NUM,1,1,1,1)\n",
    "        batch_features_ext = batch_features.unsqueeze(0).repeat(CLASS_NUM,1,1,1,1)\n",
    "        batch_features_ext = torch.transpose(batch_features_ext,0,1)\n",
    "        \n",
    "        #print ('batch_features_ext: ', batch_features_ext.size())\n",
    "        #print ('sample_features_ext: ', sample_features_ext.size())\n",
    "        \n",
    "        #[(no_of_query_images*(no_of_classes**2)), [CHANNEL_dim*2], dims, dims]\n",
    "        relation_pairs = torch.cat((sample_features_ext,batch_features_ext),2)\n",
    "        #print ('relation_pairs after concat: ', relation_pairs.size())\n",
    "        relation_pairs = relation_pairs.view(-1,CHANNEL_DIM*2,DIMS,DIMS)\n",
    "        #print ('relation_pairs before RN view: ', relation_pairs.size())\n",
    "        relation_pairs = self.rn_layer1(relation_pairs)\n",
    "        relation_pairs = self.rn_layer2(relation_pairs)\n",
    "        #print ('relation_pairs after rn layer 2: ', relation_pairs.size())\n",
    "        relation_pairs = relation_pairs.view(relation_pairs.size(0),-1)\n",
    "        #print ('relation_pairs before FCN: ', relation_pairs.size())\n",
    "        relation_pairs = F.relu(self.rn_fc1(relation_pairs))\n",
    "        relation_pairs = F.sigmoid(self.rn_fc2(relation_pairs))\n",
    "        return relation_pairs\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        n = m.weight.size(1)\n",
    "        m.weight.data.normal_(0, 0.01)\n",
    "        m.bias.data = torch.ones(m.bias.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_single_model():\n",
    "    writer = SummaryWriter('/home/caffe/achu/logs/pytorch_omniglot_full_RN_FSL_log')\n",
    "    # Step 1: init data folders\n",
    "    print(\"init data folders\")\n",
    "    # init character folders for dataset construction\n",
    "    metatrain_character_folders,metatest_character_folders = tgrn.omniglot_character_folders()\n",
    "\n",
    "    # Step 2: init neural networks\n",
    "    print(\"init neural networks\")\n",
    "\n",
    "    relation_network = CNN_Plus_RNEncoder()\n",
    "    relation_network.apply(weights_init)\n",
    "    relation_network.cuda(GPU)\n",
    "    relation_network_optim = torch.optim.Adam(relation_network.parameters(),lr=LEARNING_RATE)\n",
    "    relation_network_scheduler = StepLR(relation_network_optim,step_size=100000,gamma=0.5)\n",
    "    relation_network, relation_network_optim = amp.initialize(relation_network, relation_network_optim, opt_level=\"O2\", keep_batchnorm_fp32=True, loss_scale=\"dynamic\")\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        relation_network = nn.DataParallel(relation_network)\n",
    "    else:\n",
    "        relation_network.cuda(GPU)\n",
    "\n",
    "\n",
    "    if os.path.exists(str(\"./models/omniglot_full_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")):\n",
    "        relation_network.load_state_dict(torch.load(str(\"./models/omniglot_full_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"), map_location='cuda:0'))\n",
    "        print(\"load full relation network success\")\n",
    "\n",
    "    # Step 3: build graph\n",
    "    print(\"Training...\")\n",
    "\n",
    "    last_accuracy = 0.0\n",
    "\n",
    "    for episode in range(EPISODE):\n",
    "\n",
    "        relation_network_scheduler.step(episode)\n",
    "\n",
    "        # init dataset\n",
    "        # sample_dataloader is to obtain previous samples for compare\n",
    "        # batch_dataloader is to batch samples for training\n",
    "        degrees = random.choice([0,90,180,270])\n",
    "        task = tgrn.OmniglotTask(metatrain_character_folders,CLASS_NUM,SAMPLE_NUM_PER_CLASS,QUERY_NUM_PER_CLASS)\n",
    "        sample_dataloader = tgrn.get_data_loader(task, image_size = IMAGE_SIZE, num_per_class=SAMPLE_NUM_PER_CLASS,split=\"train\",shuffle=False,rotation=degrees)\n",
    "        batch_dataloader = tgrn.get_data_loader(task, image_size = IMAGE_SIZE, num_per_class=QUERY_NUM_PER_CLASS,split=\"test\",shuffle=True,rotation=degrees)\n",
    "\n",
    "\n",
    "        # sample datas\n",
    "        samples,sample_labels = sample_dataloader.__iter__().next()\n",
    "        batches,batch_labels = batch_dataloader.__iter__().next()\n",
    "        \n",
    "        relation_scores = relation_network(Variable(samples).cuda(GPU), Variable(batches).cuda(GPU))\n",
    "        relations = relation_scores.view(-1,CLASS_NUM)\n",
    "\n",
    "        mse = nn.MSELoss().cuda(GPU)\n",
    "        one_hot_labels = Variable(torch.zeros(QUERY_NUM_PER_CLASS*CLASS_NUM, CLASS_NUM).scatter_(1, batch_labels.view(-1,1), 1)).cuda(GPU)\n",
    "        loss = mse(relations,one_hot_labels)\n",
    "\n",
    "\n",
    "        # training\n",
    "\n",
    "        relation_network.zero_grad()\n",
    "        \n",
    "        #Mixed precision option\n",
    "        if True:\n",
    "            torch.nn.utils.clip_grad_norm_(amp.master_params(relation_network_optim),0.5)\n",
    "            with amp.scale_loss(loss, relation_network_optim) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(relation_network.parameters(),0.5)\n",
    "        #loss.backward()\n",
    "\n",
    "\n",
    "        relation_network_optim.step()\n",
    "\n",
    "        writer.add_scalar('Training loss', loss.data, episode+1)\n",
    "\n",
    "        if (episode+1)%100 == 0:\n",
    "                print(\"episode:\",episode+1,\"loss\",loss.data)\n",
    "\n",
    "        if (episode+1)%5000 == 0:\n",
    "\n",
    "            # test\n",
    "            print(\"Testing...\")\n",
    "            total_rewards = 0\n",
    "\n",
    "            for i in range(TEST_EPISODE):\n",
    "                degrees = random.choice([0,90,180,270])\n",
    "                task = tgrn.OmniglotTask(metatest_character_folders,CLASS_NUM,SAMPLE_NUM_PER_CLASS,SAMPLE_NUM_PER_CLASS,)\n",
    "                sample_dataloader = tgrn.get_data_loader(task,IMAGE_SIZE,num_per_class=SAMPLE_NUM_PER_CLASS,split=\"train\",shuffle=False,rotation=degrees)\n",
    "                test_dataloader = tgrn.get_data_loader(task,IMAGE_SIZE,num_per_class=SAMPLE_NUM_PER_CLASS,split=\"test\",shuffle=True,rotation=degrees)\n",
    "\n",
    "                sample_images,sample_labels = sample_dataloader.__iter__().next()\n",
    "                test_images,test_labels = test_dataloader.__iter__().next()\n",
    "\n",
    "                test_labels = test_labels.cuda()\n",
    "                \n",
    "                relations = relation_network(Variable(samples).cuda(GPU), Variable(batches).cuda(GPU)).view(-1,CLASS_NUM)\n",
    "\n",
    "                _,predict_labels = torch.max(relations.data,1)\n",
    "\n",
    "                rewards = [1 if predict_labels[j]==test_labels[j] else 0 for j in range(CLASS_NUM*SAMPLE_NUM_PER_CLASS)]\n",
    "\n",
    "                total_rewards += np.sum(rewards)\n",
    "\n",
    "            test_accuracy = total_rewards/1.0/CLASS_NUM/SAMPLE_NUM_PER_CLASS/TEST_EPISODE\n",
    "\n",
    "            print(\"validation accuracy:\",test_accuracy)\n",
    "            writer.add_scalar('Validation accuracy', test_accuracy, episode+1)\n",
    "\n",
    "            if test_accuracy > last_accuracy:\n",
    "\n",
    "                # save networks                \n",
    "                torch.save(relation_network.state_dict(),str(\"./models/omniglot_full_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n",
    "\n",
    "                print(\"save networks for episode:\",episode)\n",
    "\n",
    "                last_accuracy = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init data folders\n",
      "init neural networks\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caffe/achu/anaconda2/envs/python3-pytorch/lib/python3.7/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 100 loss tensor(0.0977, device='cuda:0')\n",
      "episode: 200 loss tensor(0.0090, device='cuda:0')\n",
      "episode: 300 loss tensor(0.0012, device='cuda:0')\n",
      "episode: 400 loss tensor(3.3155e-05, device='cuda:0')\n",
      "episode: 500 loss tensor(0.0001, device='cuda:0')\n",
      "episode: 600 loss tensor(5.9385e-06, device='cuda:0')\n",
      "episode: 700 loss tensor(4.1749e-06, device='cuda:0')\n",
      "episode: 800 loss tensor(2.1081e-06, device='cuda:0')\n",
      "episode: 900 loss tensor(2.5718e-06, device='cuda:0')\n",
      "episode: 1000 loss tensor(1.5109e-06, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "main_single_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
